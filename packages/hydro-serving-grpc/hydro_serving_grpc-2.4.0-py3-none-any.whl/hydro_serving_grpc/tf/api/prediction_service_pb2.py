# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: hydro_serving_grpc/tf/api/prediction_service.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
from hydro_serving_grpc.tf.api import predict_pb2 as hydro__serving__grpc_dot_tf_dot_api_dot_predict__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='hydro_serving_grpc/tf/api/prediction_service.proto',
  package='tensorflow.serving',
  syntax='proto3',
  serialized_pb=_b('\n2hydro_serving_grpc/tf/api/prediction_service.proto\x12\x12tensorflow.serving\x1a\x1bgoogle/protobuf/empty.proto\x1a\'hydro_serving_grpc/tf/api/predict.proto\"\x9f\x01\n\x0eStatusResponse\x12@\n\x06status\x18\x01 \x01(\x0e\x32\x30.tensorflow.serving.StatusResponse.ServiceStatus\x12\x0f\n\x07message\x18\x02 \x01(\t\":\n\rServiceStatus\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07SERVING\x10\x01\x12\x0f\n\x0bNOT_SERVING\x10\x02\x32\xc5\x01\n\x11PredictionService\x12j\n\x07Predict\x12..hydrosphere.tensorflow.serving.PredictRequest\x1a/.hydrosphere.tensorflow.serving.PredictResponse\x12\x44\n\x06Status\x12\x16.google.protobuf.Empty\x1a\".tensorflow.serving.StatusResponseB\'\n%io.hydrosphere.serving.tensorflow.apib\x06proto3')
  ,
  dependencies=[google_dot_protobuf_dot_empty__pb2.DESCRIPTOR,hydro__serving__grpc_dot_tf_dot_api_dot_predict__pb2.DESCRIPTOR,])



_STATUSRESPONSE_SERVICESTATUS = _descriptor.EnumDescriptor(
  name='ServiceStatus',
  full_name='tensorflow.serving.StatusResponse.ServiceStatus',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='UNKNOWN', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='SERVING', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='NOT_SERVING', index=2, number=2,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=246,
  serialized_end=304,
)
_sym_db.RegisterEnumDescriptor(_STATUSRESPONSE_SERVICESTATUS)


_STATUSRESPONSE = _descriptor.Descriptor(
  name='StatusResponse',
  full_name='tensorflow.serving.StatusResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='status', full_name='tensorflow.serving.StatusResponse.status', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='message', full_name='tensorflow.serving.StatusResponse.message', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _STATUSRESPONSE_SERVICESTATUS,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=145,
  serialized_end=304,
)

_STATUSRESPONSE.fields_by_name['status'].enum_type = _STATUSRESPONSE_SERVICESTATUS
_STATUSRESPONSE_SERVICESTATUS.containing_type = _STATUSRESPONSE
DESCRIPTOR.message_types_by_name['StatusResponse'] = _STATUSRESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

StatusResponse = _reflection.GeneratedProtocolMessageType('StatusResponse', (_message.Message,), dict(
  DESCRIPTOR = _STATUSRESPONSE,
  __module__ = 'hydro_serving_grpc.tf.api.prediction_service_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.StatusResponse)
  ))
_sym_db.RegisterMessage(StatusResponse)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n%io.hydrosphere.serving.tensorflow.api'))

_PREDICTIONSERVICE = _descriptor.ServiceDescriptor(
  name='PredictionService',
  full_name='tensorflow.serving.PredictionService',
  file=DESCRIPTOR,
  index=0,
  options=None,
  serialized_start=307,
  serialized_end=504,
  methods=[
  _descriptor.MethodDescriptor(
    name='Predict',
    full_name='tensorflow.serving.PredictionService.Predict',
    index=0,
    containing_service=None,
    input_type=hydro__serving__grpc_dot_tf_dot_api_dot_predict__pb2._PREDICTREQUEST,
    output_type=hydro__serving__grpc_dot_tf_dot_api_dot_predict__pb2._PREDICTRESPONSE,
    options=None,
  ),
  _descriptor.MethodDescriptor(
    name='Status',
    full_name='tensorflow.serving.PredictionService.Status',
    index=1,
    containing_service=None,
    input_type=google_dot_protobuf_dot_empty__pb2._EMPTY,
    output_type=_STATUSRESPONSE,
    options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_PREDICTIONSERVICE)

DESCRIPTOR.services_by_name['PredictionService'] = _PREDICTIONSERVICE

# @@protoc_insertion_point(module_scope)
